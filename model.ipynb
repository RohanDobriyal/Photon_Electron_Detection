{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load datasets\n",
    "photon_file = \"D:/Photon_Electron_Detection/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\"\n",
    "electron_file = \"D:/Photon_Electron_Detection/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\"\n",
    "\n",
    "def load_hdf5_data(file):\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        images = np.array(f[\"X\"])\n",
    "        labels = np.array(f[\"y\"])\n",
    "    return images, labels\n",
    "\n",
    "# Load data\n",
    "photon_images, photon_labels = load_hdf5_data(photon_file)\n",
    "electron_images, electron_labels = load_hdf5_data(electron_file)\n",
    "\n",
    "# Assign labels (Photons = 0, Electrons = 1)\n",
    "photon_labels[:] = 0\n",
    "electron_labels[:] = 1\n",
    "\n",
    "# Combine both datasets\n",
    "X = np.concatenate((photon_images, electron_images), axis=0)\n",
    "y = np.concatenate((photon_labels, electron_labels), axis=0)\n",
    "\n",
    "# Normalize the images\n",
    "X = X.astype(np.float32) / 255.0\n",
    "\n",
    "# Reshape for PyTorch (Batch, Channels, Height, Width)\n",
    "X = np.expand_dims(X, axis=1)  # Add channel dimension\n",
    "\n",
    "# Train-Test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train, y_train = torch.tensor(X_train), torch.tensor(y_train)\n",
    "X_test, y_test = torch.tensor(X_test), torch.tensor(y_test)\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = data.TensorDataset(X_train, y_train)\n",
    "test_dataset = data.TensorDataset(X_test, y_test)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define ResNet-15 Model\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return torch.relu(out)\n",
    "\n",
    "class ResNet15(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet15, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = ResNetBlock(64, 128, stride=2)\n",
    "        self.layer2 = ResNetBlock(128, 256, stride=2)\n",
    "        self.layer3 = ResNetBlock(256, 512, stride=2)\n",
    "        self.fc = nn.Linear(512 * 4 * 4, 1)  # Adjust based on feature map size\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = torch.sigmoid(self.fc(out))\n",
    "        return out\n",
    "\n",
    "# Initialize model\n",
    "model = ResNet15().to(device)\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device).unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Train model\n",
    "train_model(model, train_loader, epochs=10)\n",
    "\n",
    "# Save model weights\n",
    "torch.save(model.state_dict(), \"resnet15_model.pth\")\n",
    "\n",
    "# Evaluate Model\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_scores.extend(outputs.cpu().numpy())\n",
    "\n",
    "# Compute ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Save results\n",
    "with open(\"results.txt\", \"w\") as f:\n",
    "    f.write(f\"ROC-AUC Score: {roc_auc:.4f}\\n\")\n",
    "\n",
    "print(\"Training and evaluation complete. Model and results saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
